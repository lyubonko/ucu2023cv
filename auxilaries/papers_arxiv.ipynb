{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feedparser in /Users/andriiliubonko/miniconda/envs/py39/lib/python3.9/site-packages (6.0.11)\n",
      "Requirement already satisfied: sgmllib3k in /Users/andriiliubonko/miniconda/envs/py39/lib/python3.9/site-packages (from feedparser) (1.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/andriiliubonko/miniconda/envs/py39/lib/python3.9/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/andriiliubonko/miniconda/envs/py39/lib/python3.9/site-packages (from beautifulsoup4) (2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install feedparser\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed = feedparser.parse('http://arxiv.org/rss/cs')\n",
    "len(feed['entries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "papers = []\n",
    "for entry in feed['entries']:\n",
    "    \n",
    "    soup = BeautifulSoup(entry['author'], \"html.parser\")\n",
    "    \n",
    "    paper_id = entry.id.split('/')[-1]\n",
    "    paper_title = entry['title'].split('.')[0]\n",
    "    paper_abs = entry['summary'][3:-4]\n",
    "    \n",
    "    authors = []\n",
    "    for tag in soup.find_all('a', href=True):\n",
    "        authors.append(tag.contents[0])\n",
    "    \n",
    "    paper_entry = {\n",
    "        'id': paper_id,\n",
    "        'title': paper_title,\n",
    "        'authors': authors,\n",
    "        'abstract': paper_abs\n",
    "    }\n",
    "    \n",
    "    papers.append(paper_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authors_list = [\n",
    "    # --- general\n",
    "    'Geoffrey E. Hinton',\n",
    "    # --- nlp\n",
    "    'Graham Neubig',\n",
    "    'Christopher D. Manning',  \n",
    "    'Thomas Wolf',\n",
    "    'Alexander M. Rush',\n",
    "    'Dan Jurafsky',\n",
    "    # --- conv-nets (and related stuff)\n",
    "    'Jifeng Dai',\n",
    "    'Ross Girshick',\n",
    "    'Vladlen Koltun',\n",
    "    # --- math, equivariance\n",
    "    'Taco Cohen',\n",
    "    'Max Welling',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_words = [\n",
    "    # --- nlp\n",
    "    'bert',\n",
    "    'syntax',\n",
    "    'semantics'\n",
    "    # --- math-charged\n",
    "    'equivariant',\n",
    "    'manifold',\n",
    "    'sheaf',\n",
    "    'homology',\n",
    "]\n",
    "key_words_pairs = [\n",
    "    # --- nlp\n",
    "    ('common', 'sense'),\n",
    "    ('grammatical', 'error'),   \n",
    "    # --- math\n",
    "    ('category', 'theory'),\n",
    "    ('diffential', 'geometry'),\n",
    "    ('lie', 'group'),\n",
    "    ('field', 'theory'),\n",
    "    ('optimal', 'transport')\n",
    "]\n",
    "key_words_triples = [\n",
    "    # --- nlp\n",
    "    ('grammatical', 'error', 'correction')\n",
    "]\n",
    "\n",
    "key_words_pairs = [' '.join(ks) for ks in key_words_pairs]\n",
    "key_words_triples = [' '.join(ks) for ks in key_words_triples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== author based search:\n",
      "\n",
      "Jifeng Dai\n",
      "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving\n",
      "https://arxiv.org/pdf/2312.09245.pdf\n",
      "\n",
      "Graham Neubig\n",
      "An In-depth Look at Gemini's Language Abilities\n",
      "https://arxiv.org/pdf/2312.11444.pdf\n",
      "\n",
      "Jifeng Dai\n",
      "A Survey of Reasoning with Foundation Models\n",
      "https://arxiv.org/pdf/2312.11562.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== author based search:\\n\")\n",
    "for p in papers:\n",
    "    for a in p['authors']:\n",
    "        if a in authors_list:\n",
    "            print(a)\n",
    "            print(p['title'])\n",
    "            print(\"https://arxiv.org/pdf/\" + p['id'] + \".pdf\")\n",
    "            print()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== title/abstract based search:\n",
      "\n",
      "Dynamic Syntax Mapping: A New Approach to Unsupervised Syntax Parsing\n",
      "Buvarp Gohsh, Woods Ali, Anders Michael\n",
      "https://arxiv.org/pdf/2312.14966.pdf\n",
      "\n",
      "Stacked tensorial neural networks for reduced-order modeling of a parametric partial differential equation\n",
      "Caleb G. Wagner\n",
      "https://arxiv.org/pdf/2312.14979.pdf\n",
      "\n",
      "Latents2Semantics: Leveraging the Latent Space of Generative Models for Localized Style Manipulation of Face Images\n",
      "Snehal Singh Tomar, A.N. Rajagopalan\n",
      "https://arxiv.org/pdf/2312.15037.pdf\n",
      "\n",
      "Unsupervised Auditory and Semantic Entrainment Models with Deep Neural Networks\n",
      "Jay Kejriwal, Stefan Benus, Lina M. Rojas-Barahona\n",
      "https://arxiv.org/pdf/2312.15098.pdf\n",
      "\n",
      "On the Impact of Multiple Source Code Representations on Software Engineering Tasks -- An Empirical Study\n",
      "Karthik Chandra Swarna, Noble Saji Mathews, Dheeraj Vagavolu, Sridhar Chimalakonda\n",
      "https://arxiv.org/pdf/2106.10918.pdf\n",
      "\n",
      "A Survey on Generative Diffusion Model\n",
      "Hanqun Cao, Cheng Tan, Zhangyang Gao, Yilun Xu, Guangyong Chen, Pheng-Ann Heng, Stan Z. Li\n",
      "https://arxiv.org/pdf/2209.02646.pdf\n",
      "\n",
      "Deep Manifold Learning for Reading Comprehension and Logical Reasoning Tasks with Polytuplet Loss\n",
      "Jeffrey Lu, Ivan Rodriguez\n",
      "https://arxiv.org/pdf/2304.01046.pdf\n",
      "\n",
      "L3MVN: Leveraging Large Language Models for Visual Target Navigation\n",
      "Bangguo Yu, Hamidreza Kasaei, Ming Cao\n",
      "https://arxiv.org/pdf/2304.05501.pdf\n",
      "\n",
      "The generalized Pythagorean theorem on the compactifications of certain dually flat spaces via toric geometry\n",
      "Hajime Fujita\n",
      "https://arxiv.org/pdf/2305.08422.pdf\n",
      "\n",
      "Coarse-Tuning Models of Code with Reinforcement Learning Feedback\n",
      "Abhinav Jain, Chima Adiole, Swarat Chaudhuri, Thomas Reps, Chris Jermaine\n",
      "https://arxiv.org/pdf/2305.18341.pdf\n",
      "\n",
      "Energy stable and conservative dynamical low-rank approximation for the Su-Olson problem\n",
      "Lena Baumann, Lukas Einkemmer, Christian Klingenberg, Jonas Kusch\n",
      "https://arxiv.org/pdf/2307.07538.pdf\n",
      "\n",
      "Compositional Separation of Control Flow and Data Flow\n",
      "Damian Arellanes\n",
      "https://arxiv.org/pdf/2309.06397.pdf\n",
      "\n",
      "Fine-tuning ChatGPT for Automatic Scoring\n",
      "Ehsan Latif, Xiaoming Zhai\n",
      "https://arxiv.org/pdf/2310.10072.pdf\n",
      "\n",
      "ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications\n",
      "Kamyar Zeinalipour, Mohamed Zaky Saad, Marco Maggini, Marco Gori\n",
      "https://arxiv.org/pdf/2312.01339.pdf\n",
      "\n",
      "Automatic Scoring of Students' Science Writing Using Hybrid Neural Network\n",
      "Ehsan Latif, Xiaoming Zhai\n",
      "https://arxiv.org/pdf/2312.03752.pdf\n",
      "\n",
      "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?\n",
      "Ehsan Latif, Xiaoming Zhai, Lei Liu\n",
      "https://arxiv.org/pdf/2312.10833.pdf\n",
      "\n",
      "Unsupervised Harmonic Parameter Estimation Using Differentiable DSP and Spectral Optimal Transport\n",
      "Bernardo Torres, Geoffroy Peeters, GaÃ«l Richard\n",
      "https://arxiv.org/pdf/2312.14507.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interesting_items = []\n",
    "for p in papers:\n",
    "\n",
    "    words_title = [t.lower() for t in p['title'].split(\" \")]\n",
    "    pairs_title = [w1 + ' ' + w2 for (w1, w2) in zip(words_title[:-1], words_title[1:])]\n",
    "    triples_title = [' '.join(ws) for ws in zip(words_title[:-2], words_title[1:-1], words_title[2:])]    \n",
    "    \n",
    "    words_abs = [t.lower().strip(',:;.?!') for t in p['abstract'].replace(\"\\n\",\" \").split(\" \")]\n",
    "    pairs_abs = [w1 + ' ' + w2 for (w1, w2) in zip(words_abs[:-1], words_abs[1:])]\n",
    "    triples_abs = [' '.join(ws) for ws in zip(words_abs[:-2], words_abs[1:-1], words_abs[2:])]\n",
    "    \n",
    "    found = False\n",
    "    for k in key_words:  \n",
    "        if k in words_title or k in words_abs:\n",
    "            found=True\n",
    "            break\n",
    "    if found:\n",
    "        interesting_items.append(p) \n",
    "        continue\n",
    "        \n",
    "    # pairs   \n",
    "    found = False\n",
    "    for kp in key_words_pairs:\n",
    "        if kp in pairs_title or kp in pairs_abs:\n",
    "            found=True\n",
    "            break\n",
    "    if found:\n",
    "        interesting_items.append(p)\n",
    "        continue\n",
    "        \n",
    "    # triples   \n",
    "    found = False\n",
    "    for kt in key_words_triples:\n",
    "        if kt in triples_title or kt in triples_abs:\n",
    "            found=True\n",
    "            break\n",
    "    if found:\n",
    "        interesting_items.append(p)   \n",
    "        continue\n",
    "\n",
    "print(\"=== title/abstract based search:\\n\")         \n",
    "for p in interesting_items:\n",
    "    print(p['title'])\n",
    "    print(', '.join(p['authors']))    \n",
    "    print(\"https://arxiv.org/pdf/\" + p['id'] + \".pdf\")\n",
    "    #print(p['abstract'])\n",
    "    print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
